{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvIU2TirzAx6"
      },
      "source": [
        "# Body of the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code is intended to be ran on Google Colab. This is because I am unable to run Python efficiently locally. <br />\n",
        "No more than the free tier is required, as the T4 GPU offers plenty of computational power for the below code. In fact, the free tier sooner runs out of memory allocation capabilities than into any computation on the order of 10s. <br />\n",
        "The *!uv pip install* part is due to newer versions of cuda (as of Sep 2025) not running properly on Google colab. Thanks to Dr. Ahmed Al-Refaie for the code snippet, allowing the below implementation to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd_9zkJjfKWA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!uv pip install -q --system numba-cuda==0.4.0\n",
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_normal_float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTvdaZGUfFV1"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw1MaYKkejat"
      },
      "outputs": [],
      "source": [
        "M = 100         #number of trajectories\n",
        "\n",
        "N = 5_000_000   #number of integration steps\n",
        "\n",
        "dt = 2e-3       #integration step size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWXZsoKegAVq"
      },
      "source": [
        "## Potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KABLtV3Kf-Kp"
      },
      "outputs": [],
      "source": [
        "# Device function (runs on GPU only) - this will inform the CUDA simulations\n",
        "@cuda.jit(device=True)\n",
        "def device_Vprime(x, a):\n",
        "  if x>a: return 3.0*(x-(a+2.0))*(x-a)**2 + (x-a)**3\n",
        "  elif x<-a: return 3.0*(x+(a+2.0))*(x+a)**2 + (x+a)**3\n",
        "  else: return 2.0/(5.0*a**2)*x\n",
        "\n",
        "\n",
        "#@cuda.jit(device=True)\n",
        "#def device_Vprime(x, a):\n",
        "#  return x*x*x - 3*x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgx6TDiSyMzX"
      },
      "source": [
        "## RNG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEUByDSEyMTD"
      },
      "outputs": [],
      "source": [
        "host_seed = 2**63 - 1\n",
        "# This is necessary for the xoroshiro generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M82Tp3bwgwvl"
      },
      "source": [
        "## Simulation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2UgE-XjoPgE"
      },
      "source": [
        "Initiate M parallel processes, each simulating N steps of the Overdamped Langevin equation, from the given $V'(x)$ above.\n",
        "\n",
        "Check that at no point do we convert to double, or else all this we lose a lot of optimisation... In any case the current issue is memory allocation due to the size of the arrays, not speed... Still!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L87cnXCpgx4u"
      },
      "outputs": [],
      "source": [
        "def launch_EMOL_M32(a=2.0, N=25_000, M=200, dt=np.single(1e-3), eps=0.5, blockdim=256, ic=0.0, rngseed=host_seed):\n",
        "  griddim = int(np.ceil(M/blockdim)) # for some reason np.ceil() returns double?\n",
        "  host_X = np.empty((M,N), dtype=np.single)\n",
        "  host_X[:,0] = ic\n",
        "  dev_X = cuda.to_device(host_X)\n",
        "  a = np.single(a)\n",
        "\n",
        "  rng_states = create_xoroshiro128p_states(M, seed=rngseed) # necessary for device rng\n",
        "  sqrt2epsdt = np.single(np.sqrt(2*eps*dt))\n",
        "\n",
        "  kernel_update_traj32_devrng[griddim, blockdim](dev_X, a, N, M, dt, sqrt2epsdt, rng_states)\n",
        "  cuda.synchronize()\n",
        "\n",
        "  host_X = dev_X.copy_to_host()\n",
        "  return host_X\n",
        "\n",
        "\n",
        "@cuda.jit # kernel callcable from host\n",
        "def kernel_update_traj32_devrng(dev_X, a, N, M, dt, sqrt2epsdt, rng_states):\n",
        "  # a kernel function that uses xoroshiro pseudo-rng to generate noises matrix\n",
        "  glob_idx = cuda.grid(1)\n",
        "  if glob_idx >= M:\n",
        "    return\n",
        "  x = dev_X[glob_idx, 0]\n",
        "  for i in range(N-1):\n",
        "    noise = xoroshiro128p_normal_float32(rng_states, glob_idx)\n",
        "    x = kernel_1stepEMOL(x, a, sqrt2epsdt, dt, noise)\n",
        "    dev_X[glob_idx, i+1] = x\n",
        "\n",
        "\n",
        "@cuda.jit(device=True) # device function\n",
        "def kernel_1stepEMOL(x, a, sqrt2epsdt, dt, noise):\n",
        "  drift = -device_Vprime(x, a) * dt\n",
        "  diff = sqrt2epsdt * noise\n",
        "  x += drift + diff\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAwtQHr1dag"
      },
      "source": [
        "## Running Simulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = launch_EMOL_M32(a=2.0, M=M, N=N, dt=dt, blockdim=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCLgGtmp465m"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.hist(X.flatten(), bins=800, density=True, alpha=0.7, align=\"mid\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Histogram of X values\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5RwIFKAjyF-j"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
