{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0809e23e",
   "metadata": {},
   "source": [
    "# Body of the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb1e17",
   "metadata": {},
   "source": [
    "I feel that the following code is not very optimised. Still, it uses a bit of interesting maths and thought it was worth noting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97de5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4a232",
   "metadata": {},
   "source": [
    "Below code takes input (M, N) array, X (e.g. output of the CUDA E-M OL integrator code), where M is the number of trajectories stored in X, and N is the number of integration steps taken when generating X. <br />\n",
    "For the plotting, we require the corresponding dt, also specified when generating X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f2a0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def acovs_WK_unbiased(X): # host function\n",
    "  acovs = np.empty((np.shape(X)))\n",
    "  for i in range(np.shape(X)[0]):\n",
    "    acovs[i] = traj_acov_WK_unbiased(X[i])\n",
    "  return acovs\n",
    "\n",
    "def traj_acov_WK_unbiased(traj): # host function\n",
    "  x = traj - np.mean(traj)\n",
    "  n = len(x)\n",
    "  npad = 1 << (2*n-1).bit_length() # zero-padding for fft\n",
    "  # This line is cool but fucking unreadable, consider replacing with:\n",
    "  #npad = 2 ** (2*n-1).bit_length() # or something similar, like\n",
    "  #npad = 2 ** np.log(2*n-1)/np.log(2) # this is clearly inefficient lol\n",
    "  Fx = np.fft.rfft(x, n=npad)\n",
    "  ps = Fx * np.conjugate(Fx) # power spectrum - see Weiner Khinchin\n",
    "  acov = np.fft.irfft(ps, n=npad)\n",
    "  acov = acov[:n]\n",
    "  count = np.arange(n, 0, -1) # counts for unbiased weighting; n, n-1, ..., 1\n",
    "  return acov/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd159f8",
   "metadata": {},
   "source": [
    "Let's break apart the traj_acov_WK_unbiased() function. <br />\n",
    "This function takes in a trajectory from X as an input. It is a (1,N) dimensional array. <br />\n",
    "> x = traj - np.mean(traj) <br />\n",
    "\n",
    "acov requires mean-zero data <br />\n",
    "<br />\n",
    "\n",
    "> n = len(x) <br />\n",
    "> npad = 1 << (2*n-1).bit_length()\n",
    "\n",
    "Zero-padding our length for efficiency.\n",
    "3 things to unpack here: <br />\n",
    "- n = len(x) is self-explanatory, it is the exact same as N (number of integration steps)\n",
    "- NUMBER.bit_length() returns the number of bits required to represent a number in binary.\n",
    "    - $4(b10) = 100(b2)$\n",
    "    - $5(b10) = 101(b2)$\n",
    "    - both require 3 bits to be represented - this function is basically just a more efficient ceil(log_2(NUMBER))\n",
    "- L << R operator is a bitwise operator - tells you to shift bits of the number L by R bits;\n",
    "    - $1 << 3 = 100(b2) = 4(b10)$\n",
    "    - $5 << 4 = 1010000(b2) = 80(b10)$\n",
    "    - $1 << k = 2^k(b10)$\n",
    "- Why $(2n-1)$? Because we want to extend our trajectory array length to the next power of 2. Fast Fourier Transform (FFT) is the most efficient when operated on a length $2^k$ array for any integer $k$. <br />\n",
    "<br />\n",
    "\n",
    "> Fx = np.fft.rfft(x, n=npad)\n",
    "\n",
    "Taking the Fourier transform (discrete) of our mean-corrected trajectory vector. This specific implementation is using the real fast Fourier transform (rfft) (no need to use fft which works with complex128 dtype for our implementation here). <br />\n",
    "Now, why do we do this? This is the interesting part. <br />\n",
    "<br />\n",
    "\n",
    "> ps = Fx * np.conjugate(Fx)\n",
    "\n",
    "By the Weiner-Khinchin theorem, we have that the Autocorrelation function [\\*check this: need proper referencing; is it autocorrelation or autocovariance function?] is the Fourier transform of its power spectral density [\\* check this: power spectral density definition?]. <br />\n",
    "<br />\n",
    "\n",
    "> acov = np.fft.irfft(ps, n=npad)\n",
    "\n",
    "taking the inverse Fourier transform of the power spectrum <br />\n",
    "<br />\n",
    "\n",
    "> acov = acov[:n]\n",
    "\n",
    "Remove zero-padding. <br />\n",
    "<br />\n",
    "\n",
    "> count = np.arange(n, 0, -1) <br />\n",
    "> return acov/count\n",
    "\n",
    "Here, count returns number of time signals used for computation of acovariance. This is required for the unbiased normalisation of the acovariance into autocorrelation!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
